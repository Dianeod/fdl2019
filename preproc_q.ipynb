{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDL 2019 - Floods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in any libraries and datasets needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp:.p.import[`geopandas]\n",
    "\\l ml/ml.q \n",
    "\\l ml/init.q\n",
    "\\l ml/fresh/notebooks/graphics.q\n",
    "\n",
    "avs:.p.import[`sklearn.metrics]`:average_precision_score\n",
    "mattab:{flip value flip x}\n",
    "svc:.p.import[`sklearn.svm]`:SVC\n",
    "array:.p.import[`numpy]`:array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets include\n",
    "\n",
    "Max height per day per stream\n",
    "\n",
    "NLCD(imperveous) dataset collected in 2006,2011,2016\n",
    "\n",
    "Flood warned levels from NOAA, based on lat,long\n",
    "\n",
    "stream gage info i.e location,state, codes etc\n",
    "\n",
    "basin attributes at each stream gage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlcd06:(\"S\",(5#\"F\"),\"SFFSFSFFFFSFSSFSSFFFSFFSFF\";enlist \",\") 0:`:data/snap_sampled_imp_nlcd_2006.csv \n",
    "nlcd11:(\"S\",(5#\"F\"),\"SFFSFSFFFFSFSSFSSFFFSFFSFF\";enlist \",\") 0:`:data/snap_sampled_imp_nlcd_2011.csv \n",
    "nlcd16:(\"S\",(5#\"F\"),\"SFFSFSFFFFSFSSFSSFFFSFFSFF\";enlist \",\") 0:`:data/snap_sampled_imp_nlcd_2016.csv \n",
    "\n",
    "warnings:gp[`:read_file][\"data/national_shapefile_obs.shp\"]\n",
    "warnings:.ml.df2tab[warnings]\n",
    "\n",
    "gages:(\"SSSSFFSSIFFFFFFFFSSISSSSFF\";enlist \",\") 0:`:data/usgs_gage_subset.csv\n",
    "\n",
    "basin:(\"S\",242#\"F\";enlist \",\") 0:`:data/gages_with_basin_attr.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linking the stream gages with corresponding rain gages based on site_no and date (per month). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\l gagesdir/gagesdir  /will change name of loaddir\n",
    "\n",
    "maxht:0!select max height by site_no,date from str\n",
    "\n",
    "maxht[`site_no]:`${$[7=count x;\"0\",x;x]}each maxht[`site_no]\n",
    "\n",
    "maxht:delete from maxht where height<0\n",
    "\n",
    "gages[`site_no]:`${$[7=count x;\"0\",x;x]}each string each gages[`site_no] /pad with 0 if len site=7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\cd ../../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the rain data from prism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no long     lat     elv  date       ppt \n",
      "---------------------------------------------\n",
      "1367690 -74.5596 41.1053 1056 2019.01.01 0.94\n",
      "1367690 -74.5596 41.1053 1056 2019.01.02 0   \n",
      "1367690 -74.5596 41.1053 1056 2019.01.03 0   \n",
      "1367690 -74.5596 41.1053 1056 2019.01.04 0   \n",
      "1367690 -74.5596 41.1053 1056 2019.01.05 0.38\n",
      "1367690 -74.5596 41.1053 1056 2019.01.06 0.79\n",
      "1367690 -74.5596 41.1053 1056 2019.01.07 0   \n",
      "1367690 -74.5596 41.1053 1056 2019.01.08 0.02\n",
      "1367690 -74.5596 41.1053 1056 2019.01.09 0.15\n",
      "1367690 -74.5596 41.1053 1056 2019.01.10 0   \n",
      "1367690 -74.5596 41.1053 1056 2019.01.11 0   \n",
      "1367690 -74.5596 41.1053 1056 2019.01.12 0   \n",
      "1367690 -74.5596 41.1053 1056 2019.01.13 0   \n",
      "1367690 -74.5596 41.1053 1056 2019.01.14 0   \n",
      "1367690 -74.5596 41.1053 1056 2019.01.15 0   \n",
      "1367690 -74.5596 41.1053 1056 2019.01.16 0   \n",
      "1367690 -74.5596 41.1053 1056 2019.01.17 0   \n",
      "1367690 -74.5596 41.1053 1056 2019.01.18 0.06\n",
      "1367690 -74.5596 41.1053 1056 2019.01.19 0   \n",
      "1367690 -74.5596 41.1053 1056 2019.01.20 1.02\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "show precipall:raze {flip `site_no`long`lat`elv`date`ppt!flip value each 10_(\"SFFFDF\";enlist \",\")0: \n",
    "    hsym `$\"data/prism/\",string[x]} each key `:data/prism\n",
    "\n",
    "precipall[`site_no]:`${$[7=count x;\"0\",x;x]}each string each precipall[`site_no]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rain sites are missing the last digits of their id number so have to preprocess to get it to match the stream gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`precipall`precipall`precipall`precipall`precipall`precipall`precipall`precip..\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`precipall`precipall\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms:asc ds where 12<count each string each ds:exec distinct site_no from gages \n",
    "names:0!select i by site_no from precipall where site_no in `$12#'string each rms\n",
    "\n",
    "{![`precipall;enlist (in;`i;y);0b;(enlist `site_no)!enlist enlist x]}'[rms[til[20],23 24 25];\n",
    "    names[`x][til[19],21 22 23 24]]\n",
    "\n",
    "matchnames:0!select i by lat,long from precipall where i in names[`x][20]\n",
    "{![`precipall;enlist (in;`i;y);0b;(enlist `site_no)!enlist enlist x]}'[rms[21 22];matchnames[`x]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get stats on each rain gage per month,uid (id of raingage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no  date    lat     long     elevation sumpr maxpre avgpre     varpre    \n",
      "------------------------------------------------------------------------------\n",
      "01200000 2009.07 41.6588 -73.5287 456       8.01  2.04   0.2583871  0.2031039 \n",
      "01200000 2009.08 41.6588 -73.5287 456       5.94  1.59   0.1916129  0.1258458 \n",
      "01200000 2009.09 41.6588 -73.5287 456       1.55  0.85   0.05166667 0.02672056\n",
      "01200000 2009.10 41.6588 -73.5287 456       4.51  1.46   0.1454839  0.1004828 \n",
      "01200000 2009.11 41.6588 -73.5287 456       1.52  0.49   0.05066667 0.01351289\n",
      "01200000 2009.12 41.6588 -73.5287 456       5.61  0.93   0.1809677  0.08818939\n",
      "01200000 2010.01 41.6588 -73.5287 456       2.82  1.75   0.09096774 0.0974539 \n",
      "01200000 2010.02 41.6588 -73.5287 456       4.41  2.28   0.1575     0.1941045 \n",
      "01200000 2010.03 41.6588 -73.5287 456       6.5   1.36   0.2096774  0.1715322 \n",
      "01200000 2010.04 41.6588 -73.5287 456       2.17  0.57   0.07233333 0.01860456\n",
      "01200000 2010.05 41.6588 -73.5287 456       1.93  0.69   0.06225806 0.01854651\n",
      "01200000 2010.06 41.6588 -73.5287 456       3.12  0.73   0.104      0.03363733\n",
      "01200000 2010.07 41.6588 -73.5287 456       2.39  0.56   0.07709677 0.02474964\n",
      "01200000 2010.08 41.6588 -73.5287 456       5.81  2.7    0.1874194  0.2565869 \n",
      "01200000 2010.09 41.6588 -73.5287 456       1.95  0.74   0.065      0.03039167\n",
      "01200000 2010.10 41.6588 -73.5287 456       8.96  3.1    0.2890323  0.5052797 \n",
      "01200000 2010.11 41.6588 -73.5287 456       3.19  1.15   0.1063333  0.07340989\n",
      "01200000 2010.12 41.6588 -73.5287 456       4.74  1.8    0.1529032  0.19124   \n",
      "01200000 2011.01 41.6588 -73.5287 456       3.33  0.92   0.1074194  0.03784495\n",
      "01200000 2011.02 41.6588 -73.5287 456       3.45  1.09   0.1232143  0.0569861 \n",
      "..\n"
     ]
    }
   ],
   "source": [
    "show rainmonth:1_0!select first distinct lat,first distinct long,elevation:distinct elv,sumpr:sum ppt,\n",
    "    maxpre:max ppt,avgpre:avg ppt,varpre:var ppt by site_no\n",
    "    ,\"m\"$date from precipall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basin Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take out columns that depend on the date like 09,10,11. Link it with previous table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols09:where (count each ss[;\"2006\"]each string each cols basin)<>0\n",
    "cols10:where (count each ss[;\"2010\"]each string each cols basin)<>0\n",
    "cols11:where (count each ss[;\"2011\"]each string each cols basin)<>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no  date    lat     long     elevation sumpr maxpre avgpre     varpre   ..\n",
      "-----------------------------------------------------------------------------..\n",
      "01200000 2009.07 41.6588 -73.5287 456       8.01  2.04   0.2583871  0.2031039..\n",
      "01200000 2009.08 41.6588 -73.5287 456       5.94  1.59   0.1916129  0.1258458..\n",
      "01200000 2009.09 41.6588 -73.5287 456       1.55  0.85   0.05166667 0.0267205..\n",
      "01200000 2009.10 41.6588 -73.5287 456       4.51  1.46   0.1454839  0.1004828..\n",
      "01200000 2009.11 41.6588 -73.5287 456       1.52  0.49   0.05066667 0.0135128..\n",
      "01200000 2009.12 41.6588 -73.5287 456       5.61  0.93   0.1809677  0.0881893..\n",
      "01200000 2010.01 41.6588 -73.5287 456       2.82  1.75   0.09096774 0.0974539..\n",
      "01200000 2010.02 41.6588 -73.5287 456       4.41  2.28   0.1575     0.1941045..\n",
      "01200000 2010.03 41.6588 -73.5287 456       6.5   1.36   0.2096774  0.1715322..\n",
      "01200000 2010.04 41.6588 -73.5287 456       2.17  0.57   0.07233333 0.0186045..\n",
      "01200000 2010.05 41.6588 -73.5287 456       1.93  0.69   0.06225806 0.0185465..\n",
      "01200000 2010.06 41.6588 -73.5287 456       3.12  0.73   0.104      0.0336373..\n",
      "01200000 2010.07 41.6588 -73.5287 456       2.39  0.56   0.07709677 0.0247496..\n",
      "01200000 2010.08 41.6588 -73.5287 456       5.81  2.7    0.1874194  0.2565869..\n",
      "01200000 2010.09 41.6588 -73.5287 456       1.95  0.74   0.065      0.0303916..\n",
      "01200000 2010.10 41.6588 -73.5287 456       8.96  3.1    0.2890323  0.5052797..\n",
      "01200000 2010.11 41.6588 -73.5287 456       3.19  1.15   0.1063333  0.0734098..\n",
      "01200000 2010.12 41.6588 -73.5287 456       4.74  1.8    0.1529032  0.19124  ..\n",
      "01200000 2011.01 41.6588 -73.5287 456       3.33  0.92   0.1074194  0.0378449..\n",
      "01200000 2011.02 41.6588 -73.5287 456       3.45  1.09   0.1232143  0.0569861..\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "constcols:(til count[cols basin]) except raze \n",
    "    {where (count each ss[;x]each string each cols basin)<>0}each (\"2009\";\"2010\";\"2011\")\n",
    "\n",
    "basinupd:flip (cols basin)[constcols]!basin[(cols basin)[constcols]]\n",
    "\n",
    "show joinedtab:rainmonth ij `site_no xkey basinupd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLCD Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join NLCD (impervious info) to each station based on date. Only 3 datasets so link back in time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only pick columns with some variance between stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlcd06:update site_no:`${$[7=count x;\"0\",x;x]}each string each site_no,year:6 from select\n",
    " site_no:SOURCE_FEA,INTPTLAT,INTPTLON,Measure,REACHCODE,distance,imp:imp_nlcd_2006 from nlcd06\n",
    "nlcd11:update site_no:`${$[7=count x;\"0\",x;x]}each string each site_no,year:11 from select\n",
    " site_no:SOURCE_FEA,INTPTLAT,INTPTLON,Measure,REACHCODE,distance,imp:imp_nlcd_2011 from nlcd11\n",
    "nlcd16:update site_no:`${$[7=count x;\"0\",x;x]}each string each site_no,year:16 from select\n",
    " site_no:SOURCE_FEA,INTPTLAT,INTPTLON,Measure,REACHCODE,distance,imp:imp_nlcd_2016 from nlcd16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stryear:{$[x<2011;6;x<2016;11;16]}each `year$joinedtab[`date]\n",
    "\n",
    "merged:update year:stryear from joinedtab\n",
    "\n",
    "newjoinedtab:merged ij `site_no xkey (nlcd06,nlcd11,nlcd16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Target Data\n",
    "\n",
    "Get the count per month that a station goes over a flood level, broken up into 4 categories-Action,Flood,Moderate and Major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "/Some gages have no threshold values so had to delete them from dataset\n",
    "dela:first asc exec i by Action from warnings\n",
    "delmj:first 1_asc exec i by Major from warnings\n",
    "delmd:first 2_asc exec i by Moderate from warnings\n",
    "delfl:first 2_asc exec i by Flood from warnings\n",
    "\n",
    "warning:update nn: i from select from warnings where not i in distinct (dela,delmj,delmd,delfl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join based on nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabw:.ml.clust.kd.buildtree[warnlatl:raze each warning[`Latitude`Longitude],'gages[`dec_lat_va`dec_long_v];2]\n",
    "\n",
    "nnwarn:.ml.clust.kd.i.nns[;tabw;(count[warning]#0),count[gages]#1;flip warnlatl;`edist\n",
    "    ]each count[warning]+til count gages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "joins:flip `nn`ndw`site_no!(nnwarn[;0];nnwarn[;1];gages[`site_no])\n",
    "\n",
    "floodlvl:(maxht ij `site_no xkey joins) lj `nn xkey warning\n",
    "\n",
    "floodlvl[`Action`Moderate`Flood`Major]:\"F\"$'floodlvl[`Action`Moderate`Flood`Major]\n",
    "\n",
    "floodlvl[`site_no]:`${$[7=count x;\"0\",x;x]}each string each floodlvl[`site_no] /pad with 0 if len site=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no  date    Action Flood Moderate Major no_Action no_Flood no_Mod no_Major\n",
      "-------------------------------------------------------------------------------\n",
      "01200000 2009.07 6      9     10       12    0         0        0      0       \n",
      "01200000 2009.08 6      9     10       12    0         0        0      0       \n",
      "01200000 2009.09 6      9     10       12    0         0        0      0       \n",
      "01200000 2009.10 6      9     10       12    0         0        0      0       \n",
      "01200000 2009.11 6      9     10       12    0         0        0      0       \n",
      "01200000 2009.12 6      9     10       12    0         0        0      0       \n",
      "01200000 2010.01 6      9     10       12    0         0        0      0       \n",
      "01200000 2010.02 6      9     10       12    0         0        0      0       \n",
      "01200000 2010.03 6      9     10       12    1         0        0      0       \n",
      "01200000 2010.04 6      9     10       12    0         0        0      0       \n",
      "01200000 2010.05 6      9     10       12    0         0        0      0       \n",
      "01200000 2010.06 6      9     10       12    0         0        0      0       \n",
      "01200000 2010.07 6      9     10       12    0         0        0      0       \n",
      "01200000 2010.08 6      9     10       12    0         0        0      0       \n",
      "01200000 2010.09 6      9     10       12    0         0        0      0       \n",
      "01200000 2010.10 6      9     10       12    0         0        0      0       \n",
      "01200000 2010.11 6      9     10       12    0         0        0      0       \n",
      "01200000 2010.12 6      9     10       12    0         0        0      0       \n",
      "01200000 2011.01 6      9     10       12    0         0        0      0       \n",
      "01200000 2011.02 6      9     10       12    0         0        0      0       \n",
      "..\n"
     ]
    }
   ],
   "source": [
    "show target:0!select distinct Action,distinct Flood,distinct Moderate,distinct Major,no_Action:count where \n",
    " height>Action,no_Flood:count where height>Flood,no_Mod:count where height>Moderate,no_Major:count where \n",
    " height>Major by site_no,\"m\"$date from floodlvl where ndw<0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no  date    lat     long     elevation sumpr maxpre avgpre     varpre   ..\n",
      "-----------------------------------------------------------------------------..\n",
      "01200000 2009.07 41.6588 -73.5287 456       8.01  2.04   0.2583871  0.2031039..\n",
      "01200000 2009.08 41.6588 -73.5287 456       5.94  1.59   0.1916129  0.1258458..\n",
      "01200000 2009.09 41.6588 -73.5287 456       1.55  0.85   0.05166667 0.0267205..\n",
      "01200000 2009.10 41.6588 -73.5287 456       4.51  1.46   0.1454839  0.1004828..\n",
      "01200000 2009.11 41.6588 -73.5287 456       1.52  0.49   0.05066667 0.0135128..\n",
      "01200000 2009.12 41.6588 -73.5287 456       5.61  0.93   0.1809677  0.0881893..\n",
      "01200000 2010.01 41.6588 -73.5287 456       2.82  1.75   0.09096774 0.0974539..\n",
      "01200000 2010.02 41.6588 -73.5287 456       4.41  2.28   0.1575     0.1941045..\n",
      "01200000 2010.03 41.6588 -73.5287 456       6.5   1.36   0.2096774  0.1715322..\n",
      "01200000 2010.04 41.6588 -73.5287 456       2.17  0.57   0.07233333 0.0186045..\n",
      "01200000 2010.05 41.6588 -73.5287 456       1.93  0.69   0.06225806 0.0185465..\n",
      "01200000 2010.06 41.6588 -73.5287 456       3.12  0.73   0.104      0.0336373..\n",
      "01200000 2010.07 41.6588 -73.5287 456       2.39  0.56   0.07709677 0.0247496..\n",
      "01200000 2010.08 41.6588 -73.5287 456       5.81  2.7    0.1874194  0.2565869..\n",
      "01200000 2010.09 41.6588 -73.5287 456       1.95  0.74   0.065      0.0303916..\n",
      "01200000 2010.10 41.6588 -73.5287 456       8.96  3.1    0.2890323  0.5052797..\n",
      "01200000 2010.11 41.6588 -73.5287 456       3.19  1.15   0.1063333  0.0734098..\n",
      "01200000 2010.12 41.6588 -73.5287 456       4.74  1.8    0.1529032  0.19124  ..\n",
      "01200000 2011.01 41.6588 -73.5287 456       3.33  0.92   0.1074194  0.0378449..\n",
      "01200000 2011.02 41.6588 -73.5287 456       3.45  1.09   0.1232143  0.0569861..\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "show allmerged:newjoinedtab ij `site_no`date xkey target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "/Tidy up some column types\n",
    "allmerged[`lat`long]:raze each \"F\"$'string each allmerged[`lat`long]\n",
    "allmerged[`Action]:raze allmerged[`Action]\n",
    "allmerged[`Flood]:raze allmerged[`Flood]\n",
    "allmerged[`Moderate]:raze allmerged[`Moderate]\n",
    "allmerged[`Major]:raze allmerged[`Major]\n",
    "allmerged[`elevation]:raze allmerged[`elevation]\n",
    "\n",
    "/add cosin of month\n",
    "allmerged:update month:`mm$date,cos_t:cos 2*3.14*(`mm$date)%12,sin_t:sin 2*3.14*(`mm$date)%12 from allmerged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Features Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add lagged features. Previous data about rainfall/stream gages are also an important feature needed to measure if a river will flood or not. The lagged stream features that will be extracted are:\n",
    "\n",
    "      - The stream gage level was at a given stream a year prior\n",
    "      - The average gage level over the last 3 months \n",
    "      - The average stream level over it's lifetime until the given date\n",
    "      \n",
    "\n",
    "The lagged rainfall features that will be extracted are:\n",
    "    \n",
    "       -The max,avg and variance rainfall for a given streamgage for the previous 1,2 and 3 months\n",
    "       -The rainfall that occured at the 3 gages upstream at that given time (The USGS orders the stream numbers in an ascending order. The first 2 digits correspond with the basin the stream belongs to, while the remaining digits are the order that the given basin appears in the stream (upstream to downstream)\n",
    "       \n",
    " \n",
    "NOTE: This model is strictly for use on streams with gage history. These features will not be applied to ungaged basins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date    site_no  lat     long     elevation sumpr maxpre avgpre    varpre    ..\n",
      "-----------------------------------------------------------------------------..\n",
      "2009.07 01200000 41.6588 -73.5287 456       8.01  2.04   0.2583871 0.2031039 ..\n",
      "2009.07 01302020 40.8623 -73.8744 115       5.64  0.9    0.1819355 0.06038335..\n",
      "2009.07 01303000 40.8875 -73.5636 118       4.72  1.24   0.1522581 0.06770135..\n",
      "2009.07 01303500 40.8572 -73.4633 112       4.49  1.22   0.1448387 0.08244433..\n",
      "2009.07 01304000 40.8494 -73.2242 59        5.59  2.14   0.1803226 0.2114805 ..\n",
      "2009.07 01304500 40.9136 -72.6867 20        5.77  2.09   0.186129  0.1817528 ..\n",
      "2009.07 01305000 40.8303 -72.9061 62        6.31  2.65   0.2035484 0.2794874 ..\n",
      "2009.07 01305500                                                             ..\n",
      "2009.07 01306460 40.7719 -73.1586 52        6.21  2.19   0.2003226 0.2373128 ..\n",
      "2009.07 01308000 40.7042 -73.3139 20        4.97  1.38   0.1603226 0.1314289 ..\n",
      "2009.07 01308500 40.7086 -73.3283 20        4.97  1.38   0.1603226 0.1314289 ..\n",
      "2009.07 01309500 40.6889 -73.4547 49        4.88  1.34   0.1574194 0.1072901 ..\n",
      "2009.07 01310500                                                             ..\n",
      "2009.07 01311500 40.6636 -73.7044 20        4.43  0.64   0.1429032 0.04002706..\n",
      "2009.07 01315000 43.7564 -74.2672 1680      5.05  1.26   0.1629032 0.09910447..\n",
      "2009.07 01315500 43.7008 -73.9833 1293      5.41  1.31   0.1745161 0.09729573..\n",
      "2009.07 01317000 43.6094 -73.7375 951       6.83  1.46   0.2203226 0.1427967 ..\n",
      "2009.07 01318500 43.3189 -73.8442 735       7.3   2.25   0.2354839 0.2357344 ..\n",
      "2009.07 01321000 43.3528 -74.2703 1158      4.87  1.47   0.1570968 0.1080335 ..\n",
      "2009.07 01325000 43.3114 -73.8672 886       6.74  2.11   0.2174194 0.1957675 ..\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "/Join all dates within time range with stream sites so that there is no gaps in the time series\n",
    "all_dt_range:([] date:raze (count[distinct allmerged[`site_no]])#'asc distinct allmerged[`date];\n",
    "    site_no:raze flip (count[distinct allmerged[`date]])#'asc distinct allmerged[`site_no])\n",
    "\n",
    "show all_dt_merge:all_dt_range lj `site_no`date xkey allmerged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the previous stream levels of each site in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date    site_no  lagged_target_1yr lagged_target_recent lagged_target_all\n",
      "-------------------------------------------------------------------------\n",
      "2010.07 01200000 0                 0                    0                \n",
      "2010.08 01200000 0                 0                    0                \n",
      "2010.09 01200000 0                 0                    0                \n",
      "2010.10 01200000 0                 0                    0                \n",
      "2010.11 01200000 0                 0                    0                \n",
      "2010.12 01200000 0                 0                    0                \n",
      "2011.01 01200000 0                 0                    0                \n",
      "2011.02 01200000 0                 0                    0                \n",
      "2011.03 01200000 0                 0                    0.1904762        \n",
      "2011.04 01200000 0                 0                    0.1818182        \n",
      "2011.05 01200000 0                 0                    0.173913         \n",
      "2011.06 01200000 0                 4                    0.1666667        \n",
      "2011.07 01200000 0                 0                    0.16             \n",
      "2011.08 01200000 0                 0                    0.2307692        \n",
      "2011.09 01200000 0                 0                    0.2222222        \n",
      "2011.10 01200000 0                 0                    0.2142857        \n",
      "2011.11 01200000 0                 2                    0.2068966        \n",
      "2011.12 01200000 0                 0                    0.2              \n",
      "2012.01 01200000 0                 0                    0.1935484        \n",
      "2012.02 01200000 0                 0                    0.1875           \n",
      "..\n"
     ]
    }
   ],
   "source": [
    "catch_tgts:0!select site_no,no_Flood,date,cs:count date by site_no from all_dt_merge\n",
    "\n",
    "lagy:raze{12 xprev raze x}each exec no_Flood from catch_tgts\n",
    "lag1:raze{1 xprev raze x}each exec no_Flood from catch_tgts\n",
    "lag2:raze{2 xprev raze x}each exec no_Flood from catch_tgts\n",
    "lag3:raze{3 xprev raze x}each exec no_Flood from catch_tgts\n",
    "lagall:raze{count[x] mavg raze x}each exec no_Flood from catch_tgts\n",
    "\n",
    "lagavg:avg each lag1,'lag2,'lag3\n",
    "\n",
    "lagdt:([] date:raze ((catch_tgts[`cs])#'catch_tgts[`date]);site_no:raze (catch_tgts[`cs])#'catch_tgts[`site_no];\n",
    "    lagged_target_1yr:lagy;lagged_target_recent:lag3;lagged_target_all:lagall)\n",
    "\n",
    "show lagdt:delete from lagdt where i in where any flip null value each lagdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the 3 month rainfall history per site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date    site_no  avg_prev_1 avg_prev_2 avg_prev_3 max_prev_1 max_prev_2 max_p..\n",
      "-----------------------------------------------------------------------------..\n",
      "2009.10 01200000 0.05166667 0.1916129  0.2583871  0.85       1.59       2.04 ..\n",
      "2009.11 01200000 0.1454839  0.05166667 0.1916129  1.46       0.85       1.59 ..\n",
      "2009.12 01200000 0.05066667 0.1454839  0.05166667 0.49       1.46       0.85 ..\n",
      "2010.01 01200000 0.1809677  0.05066667 0.1454839  0.93       0.49       1.46 ..\n",
      "2010.02 01200000 0.09096774 0.1809677  0.05066667 1.75       0.93       0.49 ..\n",
      "2010.03 01200000 0.1575     0.09096774 0.1809677  2.28       1.75       0.93 ..\n",
      "2010.04 01200000 0.2096774  0.1575     0.09096774 1.36       2.28       1.75 ..\n",
      "2010.05 01200000 0.07233333 0.2096774  0.1575     0.57       1.36       2.28 ..\n",
      "2010.06 01200000 0.06225806 0.07233333 0.2096774  0.69       0.57       1.36 ..\n",
      "2010.07 01200000 0.104      0.06225806 0.07233333 0.73       0.69       0.57 ..\n",
      "2010.08 01200000 0.07709677 0.104      0.06225806 0.56       0.73       0.69 ..\n",
      "2010.09 01200000 0.1874194  0.07709677 0.104      2.7        0.56       0.73 ..\n",
      "2010.10 01200000 0.065      0.1874194  0.07709677 0.74       2.7        0.56 ..\n",
      "2010.11 01200000 0.2890323  0.065      0.1874194  3.1        0.74       2.7  ..\n",
      "2010.12 01200000 0.1063333  0.2890323  0.065      1.15       3.1        0.74 ..\n",
      "2011.01 01200000 0.1529032  0.1063333  0.2890323  1.8        1.15       3.1  ..\n",
      "2011.02 01200000 0.1074194  0.1529032  0.1063333  0.92       1.8        1.15 ..\n",
      "2011.03 01200000 0.1232143  0.1074194  0.1529032  1.09       0.92       1.8  ..\n",
      "2011.04 01200000 0.2216129  0.1232143  0.1074194  3.2        1.09       0.92 ..\n",
      "2011.05 01200000 0.1863333  0.2216129  0.1232143  1.98       3.2        1.09 ..\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "catch_dts:0!select date,avgpre,maxpre,varpre,cs:count i by site_no from all_dt_merge\n",
    "\n",
    "avg1:raze {1 xprev raze x}each exec avgpre from catch_dts\n",
    "avg2:raze {2 xprev raze x}each exec avgpre from catch_dts\n",
    "avg3:raze {3 xprev raze x}each exec avgpre from catch_dts\n",
    "\n",
    "\n",
    "max1:raze {1 xprev raze x}each exec maxpre from catch_dts\n",
    "max2:raze{2 xprev raze x}each exec maxpre from catch_dts\n",
    "max3:raze{3 xprev raze x}each exec maxpre from catch_dts\n",
    "\n",
    "var1:raze{1 xprev raze x}each exec varpre from catch_dts\n",
    "var2:raze{2 xprev raze x}each exec varpre from catch_dts\n",
    "var3:raze{3 xprev raze x}each exec varpre from catch_dts\n",
    "\n",
    "prevdt:([] date:raze ((catch_dts[`cs])#'catch_dts[`date]);site_no:raze (catch_dts[`cs])#'catch_dts[`site_no];\n",
    "    avg_prev_1:avg1;\n",
    "    avg_prev_2:avg2;avg_prev_3:avg3;\n",
    "    max_prev_1:max1;max_prev_2:max2;max_prev_3:max3;var_prev_1:var1;var_prev_2:var2;var_prev_3:var3)\n",
    "\n",
    "show prevdt:delete from prevdt where i in where any flip null value each prevdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the rainfall up the 3 upstream basins of a site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date    site_no  avg_ups_1 avg_ups_2 avg_ups_3 max_ups_1 max_ups_2 max_ups_3 ..\n",
      "-----------------------------------------------------------------------------..\n",
      "2009.07 01303500 0.1522581 0.1819355 0.2583871 1.24      0.9       2.04      ..\n",
      "2009.07 01304000 0.1448387 0.1522581 0.1819355 1.22      1.24      0.9       ..\n",
      "2009.07 01304500 0.1803226 0.1448387 0.1522581 2.14      1.22      1.24      ..\n",
      "2009.07 01305000 0.186129  0.1803226 0.1448387 2.09      2.14      1.22      ..\n",
      "2009.07 01305500 0.2035484 0.186129  0.1803226 2.65      2.09      2.14      ..\n",
      "2009.07 01309500 0.1603226 0.1603226 0.2003226 1.38      1.38      2.19      ..\n",
      "2009.07 01310500 0.1574194 0.1603226 0.1603226 1.34      1.38      1.38      ..\n",
      "2009.07 01317000 0.1745161 0.1629032 0.1429032 1.31      1.26      0.64      ..\n",
      "2009.07 01318500 0.2203226 0.1745161 0.1629032 1.46      1.31      1.26      ..\n",
      "2009.07 01321000 0.2354839 0.2203226 0.1745161 2.25      1.46      1.31      ..\n",
      "2009.07 01325000 0.1570968 0.2354839 0.2203226 1.47      2.25      1.46      ..\n",
      "2009.07 01327750 0.2174194 0.1570968 0.2354839 2.11      1.47      2.25      ..\n",
      "2009.07 01329490 0.2032258 0.2174194 0.1570968 1.54      2.11      1.47      ..\n",
      "2009.07 01330000 0.2474194 0.2032258 0.2174194 1.82      1.54      2.11      ..\n",
      "2009.07 01334500 0.1864516 0.2474194 0.2032258 1.32      1.82      1.54      ..\n",
      "2009.07 01335754 0.2290323 0.1864516 0.2474194 1.55      1.32      1.82      ..\n",
      "2009.07 01335755 0.2648387 0.2290323 0.1864516 3.02      1.55      1.32      ..\n",
      "2009.07 01348000 0.1645161 0.1303226 0.1519355 1.03      0.71      0.98      ..\n",
      "2009.07 01349000 0.1735484 0.1645161 0.1303226 1.18      1.03      0.71      ..\n",
      "2009.07 01349711 0.2135484 0.226129  0.1932258 2.1       2.12      1.36      ..\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "catch_atts:0!select site_no,avgpre,maxpre,varpre,cs:count i by date,catch:2#'string each site_no from all_dt_merge\n",
    "\n",
    "avg1:raze {1 xprev raze x}each exec avgpre from catch_atts\n",
    "avg2:raze {2 xprev raze x}each exec avgpre from catch_atts\n",
    "avg3:raze {3 xprev raze x}each exec avgpre from catch_atts\n",
    "\n",
    "\n",
    "max1:raze {1 xprev raze x}each exec maxpre from catch_atts\n",
    "max2:raze{2 xprev raze x}each exec maxpre from catch_atts\n",
    "max3:raze{3 xprev raze x}each exec maxpre from catch_atts\n",
    "\n",
    "var1:raze{1 xprev raze x}each exec varpre from catch_atts\n",
    "var2:raze{2 xprev raze x}each exec varpre from catch_atts\n",
    "var3:raze{3 xprev raze x}each exec varpre from catch_atts\n",
    "\n",
    "upstr:([] date:raze ((catch_atts[`cs])#'catch_atts[`date]);site_no:raze catch_atts[`site_no]; avg_ups_1:avg1;\n",
    "    avg_ups_2:avg2;avg_ups_3:avg3;\n",
    "    max_ups_1:max1;max_ups_2:max2;max_ups_3:max3;var_ups_1:var1;var_ups_2:var2;var_ups_3:var3)\n",
    "\n",
    "show upstr:delete from upstr where i in where any flip null value each upstr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join all the columns together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no  date    lat     long     elevation sumpr maxpre avgpre     varpre   ..\n",
      "-----------------------------------------------------------------------------..\n",
      "01303500 2010.07 40.8572 -73.4633 112       2.42  0.57   0.07806452 0.0261510..\n",
      "01303500 2010.08 40.8572 -73.4633 112       2.1   1.58   0.06774194 0.0788110..\n",
      "01303500 2010.09 40.8572 -73.4633 112       3.11  1.15   0.1036667  0.0659032..\n",
      "01303500 2013.12 40.8572 -73.4633 112       4.7   1.33   0.1516129  0.1197039..\n",
      "01303500 2014.01 40.8572 -73.4633 112       3     0.54   0.09677419 0.0265831..\n",
      "01303500 2014.02 40.8572 -73.4633 112       4.32  1.13   0.1542857  0.0716459..\n",
      "01303500 2014.03 40.8572 -73.4633 112       4.18  2.69   0.1348387  0.2420895..\n",
      "01303500 2014.04 40.8572 -73.4633 112       3.21  0.96   0.107      0.0531343..\n",
      "01303500 2014.05 40.8572 -73.4633 112       6.79  3.69   0.2190323  0.4428152..\n",
      "01303500 2014.06 40.8572 -73.4633 112       3.16  0.9    0.1053333  0.0478448..\n",
      "01303500 2014.07 40.8572 -73.4633 112       3.04  1.1    0.09806452 0.0502349..\n",
      "01303500 2014.08 40.8572 -73.4633 112       3.73  2.72   0.1203226  0.2344225..\n",
      "01303500 2014.09 40.8572 -73.4633 112       2.38  0.82   0.07933333 0.0373795..\n",
      "01303500 2014.10 40.8572 -73.4633 112       3.89  1.07   0.1254839  0.0600570..\n",
      "01303500 2014.11 40.8572 -73.4633 112       4.56  1      0.152      0.081856 ..\n",
      "01303500 2014.12 40.8572 -73.4633 112       6     1.88   0.1935484  0.1661003..\n",
      "01303500 2015.01 40.8572 -73.4633 112       5.2   1.54   0.1677419  0.1190433..\n",
      "01303500 2015.02 40.8572 -73.4633 112       2.15  0.75   0.07678571 0.0360003..\n",
      "01303500 2015.03 40.8572 -73.4633 112       4.43  0.68   0.1429032  0.0482399..\n",
      "01303500 2015.04 40.8572 -73.4633 112       1.95  1.04   0.065      0.0360783..\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "show added_cols:((allmerged ij `site_no`date xkey upstr) ij `site_no`date xkey prevdt) ij `site_no`date xkey lagdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgts:select site_no,no_Action,no_Flood,no_Mod,no_Major from added_cols\n",
    "added_cols:delete no_Action,no_Flood,no_Mod,no_Major from added_cols\n",
    "tabreduced:`site_no`date xkey .ml.filltab[added_cols;`site_no;`date;::]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Auto-ML we were able to extract the most important basin characteristics from the model, the lagged features were then added after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "/cols to include\n",
    "cols_to_include:\n",
    "    `site_no`date`cos_t`sin_t,\n",
    "    `elevation`imp`avgpre`maxpre`CatAreaSqKm`WsAreaSqKm`CatAreaSqKmRp100`WsAreaSqKmRp100,\n",
    "    `ElevCat`ElevWs`WtDepCat`WtDepWs`OmCat`OmWs`PermCat`PermWs`RckDepCat`RckDepWs`ClayCat`ClayWs,\n",
    "    `SandCat`SandWs`RunoffCat`RunoffWs`WetIndexCat`WetIndexWs`BFICat`BFIWs,\n",
    "    `avg_prev_1`avg_prev_2`avg_prev_3`max_prev_1`max_prev_2`max_prev_3`var_prev_1`var_prev_2,\n",
    "    `var_prev_3`avg_ups_1`avg_ups_2`avg_ups_3`max_ups_1`max_ups_2`max_ups_3`var_ups_1,`var_ups_2`var_ups_3,\n",
    "    `lagged_target_1yr`lagged_target_recent`lagged_target_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no  date   | cos_t        sin_t        elevation imp      avgpre     max..\n",
      "----------------| -----------------------------------------------------------..\n",
      "01303500 2010.07| -0.866953    -0.49839     112       14.47757 0.07806452 0.5..\n",
      "01303500 2010.08| -0.5018379   -0.8649617   112       14.47757 0.06774194 1.5..\n",
      "01303500 2010.09| -0.002388978 -0.9999971   112       14.47757 0.1036667  1.1..\n",
      "01303500 2013.12| 0.9999949    -0.003185302 112       14.47757 0.1516129  1.3..\n",
      "01303500 2014.01| 0.8661581    0.4997701    112       14.47757 0.09677419 0.5..\n",
      "01303500 2014.02| 0.5004597    0.8657598    112       14.47757 0.1542857  1.1..\n",
      "01303500 2014.03| 0.0007963267 0.9999997    112       14.47757 0.1348387  2.6..\n",
      "01303500 2014.04| -0.4990802   0.8665558    112       14.47757 0.107      0.9..\n",
      "01303500 2014.05| -0.865361    0.501149     112       14.47757 0.2190323  3.6..\n",
      "01303500 2014.06| -0.9999987   0.001592653  112       14.47757 0.1053333  0.9..\n",
      "01303500 2014.07| -0.866953    -0.49839     112       14.47757 0.09806452 1.1..\n",
      "01303500 2014.08| -0.5018379   -0.8649617   112       14.47757 0.1203226  2.7..\n",
      "01303500 2014.09| -0.002388978 -0.9999971   112       14.47757 0.07933333 0.8..\n",
      "01303500 2014.10| 0.4976994    -0.8673496   112       14.47757 0.1254839  1.0..\n",
      "01303500 2014.11| 0.8645618    -0.5025265   112       14.47757 0.152      1  ..\n",
      "01303500 2014.12| 0.9999949    -0.003185302 112       14.47757 0.1935484  1.8..\n",
      "01303500 2015.01| 0.8661581    0.4997701    112       14.47757 0.1677419  1.5..\n",
      "01303500 2015.02| 0.5004597    0.8657598    112       14.47757 0.07678571 0.7..\n",
      "01303500 2015.03| 0.0007963267 0.9999997    112       14.47757 0.1429032  0.6..\n",
      "01303500 2015.04| -0.4990802   0.8665558    112       14.47757 0.065      1.0..\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "show tabreducedn:`site_no`date xkey flip cols_to_include!(0!tabreduced)[cols_to_include]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardised scaling is preformed on some of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdtab:.ml.stdscaler[value tabreducedn]\n",
    "newtab:`site_no`date xkey (select site_no,date from 0!tabreducedn),'stdtab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test set are strictly divided so that each station is either in train or test so that there is no data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstsplt:250#distinct key[newtab][`site_no]\n",
    "trainsplt:250_distinct key[newtab][`site_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain:value select from newtab where site_no in trainsplt\n",
    "xtest:value select from newtab where site_no in tstsplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "/predict for  Moderate floods\n",
    "ytrain:(exec no_Flood from tgts where site_no in trainsplt)>0\n",
    "ytest:(exec no_Flood from tgts where site_no in tstsplt)>0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "/backfilling per site doesn't work as nulls for all site, will look more into that\n",
    "xtr:(mattab xtrain)[(til count[mattab xtrain]) except where 0<>{count where x=0n}each mattab xtrain]\n",
    "ytr:ytrain[(til count[mattab xtrain]) except where 0<>{count where x=0n}each mattab xtrain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf:.p.import[`sklearn.ensemble][`:RandomForestClassifier][`n_estimators pykw 200;`random_state pykw 1]\n",
    "clf[`:fit][xtr;ytr]`;\n",
    "pred1:clf[`:predict][mattab xtest]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class    | precision recall    f1_score  support\n",
       "---------| -------------------------------------\n",
       "0        | 0.9982263 0.9469965 0.9719368 17829  \n",
       "1        | 0.4512195 0.9628253 0.6144721 807    \n",
       "avg/total| 0.7247229 0.9549109 0.7932045 18636  \n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".ml.classreport[ytest;pred1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0| 16884 945\n",
      "1| 30    777\n",
      "The accuracy of the model is 0.9476819\n",
      "The mean_class_accuracy of the model is 0.9549109\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show cnfM:.ml.confmat[ytest;pred1]\n",
    "conf:.ml.confdict[ytest;pred1;1b]\n",
    "\n",
    "acc:(count where pred1=ytest)%count[ytest]\n",
    "meanclassavg:avg (conf[`tp]%(sum conf[`tp`fn]);conf[`tn]%(sum conf[`tn`fp]))\n",
    "\n",
    "-1\"The accuracy of the model is \",string acc;\n",
    "-1\"The mean_class_accuracy of the model is \",string meanclassavg;\n",
    ".ml.displayCM[value cnfM;`Low`High;\"Test Set Confusion Matrix\";()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import models needed for Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "tf: .p.import[`tensorflow]\n",
    "ker: .p.import[`tensorflow.keras]\n",
    "layers:.p.import[`tensorflow.keras.layers]\n",
    "dense:  .p.import[`keras.layers]`:Dense\n",
    "\n",
    "km:.p.import[`keras_metrics]\n",
    "models:.p.import[`keras]`:Model\n",
    "sequential:.p.import[`keras.models]`:Sequential\n",
    "plt:.p.import[`matplotlib]`:pyplot\n",
    "inp:.p.import[`keras.layers]`:Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0805 05:28:25.290357 139773060096000 deprecation_wrapper.py:119] From /home/dianeodonoghue/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0805 05:28:25.306104 139773060096000 deprecation_wrapper.py:119] From /home/dianeodonoghue/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0805 05:28:25.309896 139773060096000 deprecation_wrapper.py:119] From /home/dianeodonoghue/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0805 05:28:25.356362 139773060096000 deprecation_wrapper.py:119] From /home/dianeodonoghue/miniconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0805 05:28:25.373116 139773060096000 deprecation_wrapper.py:119] From /home/dianeodonoghue/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0805 05:28:25.376317 139773060096000 deprecation.py:323] From /home/dianeodonoghue/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0805 05:28:25.396944 139773060096000 deprecation_wrapper.py:119] From /home/dianeodonoghue/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,761\n",
      "Trainable params: 3,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-05 05:28:25.740573: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-08-05 05:28:25.754437: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-08-05 05:28:25.758214: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6f766a0 executing computations on platform Host. Devices:\n",
      "2019-08-05 05:28:25.758347: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-08-05 05:28:25.760561: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2019-08-05 05:28:26.316421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-05 05:28:26.317433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-08-05 05:28:26.317581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-05 05:28:26.318517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:05.0\n",
      "2019-08-05 05:28:26.318621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-05 05:28:26.319560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:06.0\n",
      "2019-08-05 05:28:26.319650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-05 05:28:26.320594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:07.0\n",
      "2019-08-05 05:28:26.321473: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-08-05 05:28:26.325932: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-08-05 05:28:26.332925: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-08-05 05:28:26.334001: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-08-05 05:28:26.343901: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-08-05 05:28:26.348166: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-08-05 05:28:26.348362: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
      "2019-08-05 05:28:26.348390: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...\n",
      "2019-08-05 05:28:26.350183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-08-05 05:28:26.350220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 \n",
      "2019-08-05 05:28:26.350236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y N N \n",
      "2019-08-05 05:28:26.350252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N N N \n",
      "2019-08-05 05:28:26.350263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   N N N Y \n",
      "2019-08-05 05:28:26.350274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   N N Y N \n",
      "2019-08-05 05:28:26.353097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-05 05:28:26.353214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-05 05:28:26.353303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-05 05:28:26.353396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-05 05:28:26.358419: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x9751310 executing computations on platform CUDA. Devices:\n",
      "2019-08-05 05:28:26.358572: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2019-08-05 05:28:26.358591: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "2019-08-05 05:28:26.358604: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5\n",
      "2019-08-05 05:28:26.358617: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5\n",
      "2019-08-05 05:28:26.510974: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.2365 - precision: 0.8750 - recall: 0.32 - ETA: 0s - loss: 0.2127 - precision: 0.8991 - recall: 0.40 - ETA: 0s - loss: 0.1921 - precision: 0.9019 - recall: 0.44 - ETA: 0s - loss: 0.1831 - precision: 0.9013 - recall: 0.45 - 1s 26us/step - loss: 0.1751 - precision: 0.9096 - recall: 0.4695\n",
      "Epoch 2/100\n",
      "20522/20522 [==============================] - 0s 15us/step - loss: 0.1149 - precision: 0.9188 - recall: 0.6129 0s - loss: 0.1299 - precision: 0.9333 - recall: 0. - ETA: 0s - loss: 0.1185 - precision: 0.9292 - recall: 0.61 - ETA: 0s - loss: 0.1162 - precision: 0.9274 - recall: 0.61 - ETA: 0s - loss: 0.1180 - precision: 0.9192 - recall: 0.\n",
      "Epoch 3/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.1062 - precision: 0.9217 - recall: 0.6318 ETA: 0s - loss: 0.1060 - precision: 0.9214 - recall: 0.65 - ETA: 0s - loss: 0.1079 - precision: 0.9226 - recall: 0.63 - ETA: 0s - loss: 0.1071 - precision: 0.9215 - recall: 0. - 0s 15us/step - loss: 0.1062 - precision: 0.9221 - recall: 0.6342\n",
      "Epoch 4/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.1003 - precision: 0.9208 - recall: 0.6434 ETA: 0s - loss: 0.0965 - precision: 0.9291 - recall:  - ETA: 0s - loss: 0.1015 - precision: 0.9229 - recall: 0.64 - 0s 14us/step - loss: 0.1012 - precision: 0.9228 - recall: 0.6469\n",
      "Epoch 5/100\n",
      "20522/20522 [==============================] - 0s 15us/step - loss: 0.0971 - precision: 0.9315 - recall: 0.6584 0s - loss: 0.0985 - precision: 0.9426 - recall: 0.65 - ETA: 0s - loss: 0.0990 - precision: 0.9326 - recall: 0.65 - ETA: 0s - loss: 0.0940 - precision: 0.9365 - recall: 0.\n",
      "Epoch 6/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0953 - precision: 1.0000 - recall: 0.42 - ETA: 0s - loss: 0.0888 - precision: 0.9167 - recall: 0.66 - ETA: 0s - loss: 0.0911 - precision: 0.9248 - recall: 0.66 - ETA: 0s - loss: 0.0965 - precision: 0.9232 - recall: 0.64 - ETA: 0s - loss: 0.0956 - precision: 0.9206 - recall: 0.65 - ETA: 0s - loss: 0.0952 - precision: 0.9253 - recall: 0.66 - 0s 15us/step - loss: 0.0946 - precision: 0.9238 - recall: 0.6705\n",
      "Epoch 7/100\n",
      "20522/20522 [==============================] - 0s 15us/step - loss: 0.0923 - precision: 0.9278 - recall: 0.6740 0s - loss: 0.0800 - precision: 0.9398 - recall: 0.69 - ETA: 0s - loss: 0.0884 - precision: 0.9191 - recall: 0.68 - ETA: 0s - loss: 0.0926 - precision: 0.9173 - recall: 0. - ETA: 0s - loss: 0.0929 - precision: 0.9240 - recall: 0.67\n",
      "Epoch 8/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0901 - precision: 0.9275 - recall: 0.6742 ETA: 0s - loss: 0.0882 - precision: 0.9218 - recall - ETA: 0s - loss: 0.0887 - precision: 0.9310 - recall: 0.67 - 0s 14us/step - loss: 0.0888 - precision: 0.9319 - recall: 0.6774\n",
      "Epoch 9/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0862 - precision: 0.9262 - recall: 0.6872 ETA: 0s - loss: 0.0928 - precision: 0.9234 - recall: 0. - ETA: 0s - loss: 0.0853 - precision: 0.9288 - recall: 0.68 - ETA: 0s - loss: 0.0851 - precision: 0.9269 - recall: 0. - 0s 15us/step - loss: 0.0872 - precision: 0.9237 - recall: 0.6838\n",
      "Epoch 10/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0839 - precision: 0.9262 - recall: 0.69 - 0s 15us/step - loss: 0.0852 - precision: 0.9237 - recall: 0.6970\n",
      "Epoch 11/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0797 - precision: 0.9448 - recall: 0.7090 ETA: 0s - loss: 0.0751 - precision: 0.9518 - recall: 0.73 - ETA: 0s - loss: 0.0786 - precision: 0.9506 - recall: 0.70 - ETA: 0s - loss: 0.0790 - precision: 0.9492 - recall: 0. - ETA: 0s - loss: 0.0813 - precision: 0.9371 - recall: 0.71 - 0s 15us/step - loss: 0.0831 - precision: 0.9340 - recall: 0.7091\n",
      "Epoch 12/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0794 - precision: 0.9283 - recall: 0.7112 ETA: 0s - loss: 0.0812 - precision: 0.9302 - recall: 0.68 - ETA: 0s - loss: 0.0778 - precision: 0.9405 - recall:  - ETA: 0s - loss: 0.0810 - precision: 0.9272 - recall: 0.71 - 0s 14us/step - loss: 0.0811 - precision: 0.9286 - recall: 0.7114\n",
      "Epoch 13/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0775 - precision: 0.9308 - recall: 0.7211 ETA: 0s - loss: 0.0812 - precision: 0.9300 - recall: 0.70 - ETA: 0s - loss: 0.0807 - precision: 0.9327 - recall: 0.71 - ETA: 0s - loss: 0.0765 - precision: 0.9351 - recall: 0. - 0s 14us/step - loss: 0.0795 - precision: 0.9274 - recall: 0.7206\n",
      "Epoch 14/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0786 - precision: 0.9287 - recall: 0.7281 0s - loss: 0.0782 - precision: 0.9240 - recall: 0. - ETA: 0s - loss: 0.0782 - precision: 0.9295 - recall: 0.73 - ETA: 0s - loss: 0.0772 - precision: 0.9281 - recall: 0.73\n",
      "Epoch 15/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0771 - precision: 0.9249 - recall: 0.7373 0s - loss: 0.0659 - precision: 0.9457 - recall: 0. - ETA: 0s - loss: 0.0758 - precision: 0.9343 - recall: 0.73 - ETA: 0s - loss: 0.0763 - precision: 0.9301 - recall: 0.\n",
      "Epoch 16/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0764 - precision: 0.9319 - recall: 0.7438 ETA: 0s - loss: 0.0764 - precision: 0.9284 - recall: 0. - 0s 13us/step - loss: 0.0754 - precision: 0.9342 - recall: 0.7442\n",
      "Epoch 17/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0740 - precision: 0.9246 - recall: 0.7417 0s - loss: 0.0663 - precision: 0.9305 - recall: 0.75 - ETA: 0s - loss: 0.0671 - precision: 0.9500 - recall: 0.76 - ETA: 0s - loss: 0.0690 - precision: 0.9369 - recall: 0.75 - ETA: 0s - loss: 0.0699 - precision: 0.9336 - recall: 0.74 - ETA: 0s - loss: 0.0734 - precision: 0.9279 - recall: 0.74\n",
      "Epoch 18/100\n",
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0735 - precision: 0.9313 - recall: 0.7500 0s - loss: 0.0779 - precision: 0.9361 - recall\n",
      "Epoch 19/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0713 - precision: 0.9297 - recall: 0.73 - ETA: 0s - loss: 0.0703 - precision: 0.9363 - recall: 0.74 - ETA: 0s - loss: 0.0712 - precision: 0.9307 - recall: 0.74 - ETA: 0s - loss: 0.0717 - precision: 0.9338 - recall: 0.75 - 0s 14us/step - loss: 0.0714 - precision: 0.9375 - recall: 0.7523\n",
      "Epoch 20/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0710 - precision: 0.9270 - recall: 0.7684 0s - loss: 0.0698 - precision: 0.9267 - recall: 0. - ETA: 0s - loss: 0.0707 - precision: 0.9281 - recall: 0. - ETA: 0s - loss: 0.0695 - precision: 0.9270 - recall: 0.76\n",
      "Epoch 21/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0678 - precision: 0.9318 - recall: 0.7729 ETA: 0s - loss: 0.0705 - precision: 0.9373 - recall: 0. - ETA: 0s - loss: 0.0654 - precision: 0.9345 - recall: 0. - 0s 14us/step - loss: 0.0695 - precision: 0.9343 - recall: 0.7702\n",
      "Epoch 22/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0678 - precision: 0.9401 - recall: 0.76 - ETA: 0s - loss: 0.0693 - precision: 0.9403 - recall: 0.77 - ETA: 0s - loss: 0.0676 - precision: 0.9360 - recall: 0.77 - ETA: 0s - loss: 0.0679 - precision: 0.9299 - recall: 0.77 - 0s 14us/step - loss: 0.0680 - precision: 0.9291 - recall: 0.7702\n",
      "Epoch 23/100\n",
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0678 - precision: 0.9284 - recall: 0.7690 0s - loss: 0.0691 - precision: 0.9188 - recall: 0.75 - ETA: 0s - loss: 0.0728 - precision: 0.9132 - recall: 0.75 - ETA: 0s - loss: 0.0693 - precision: 0.9229 - recall: \n",
      "Epoch 24/100\n",
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0664 - precision: 0.9341 - recall: 0.7840 0s - loss: 0.0619 - precision: 0.9599 - recall: 0.78 - ETA: 0s - loss: 0.0640 - precision: 0.9559 - recall: 0.79 - ETA: 0s - loss: 0.0653 - precision: 0.9472 - recall: 0.79 - ETA: 0s - loss: 0.0661 - precision: 0.9353 - recall: 0.78 - ETA: 0s - loss: 0.0670 - precision: 0.9347 - recall: 0.78\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0654 - precision: 0.9397 - recall: 0.7719 0s - loss: 0.0645 - precision: 0.9478 - recall - ETA: 0s - loss: 0.0657 - precision: 0.9410 - recall: 0.76\n",
      "Epoch 26/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0642 - precision: 0.9460 - recall: 0.7816 ETA: 0s - loss: 0.0650 - precision: 0.9580 - recall: 0. - ETA: 0s - loss: 0.0660 - precision: 0.9367 - recall: 0.77 - ETA: 0s - loss: 0.0644 - precision: 0.9376 - recall: 0.77 - ETA: 0s - loss: 0.0640 - precision: 0.9390 - recall: 0.77 - 0s 13us/step - loss: 0.0647 - precision: 0.9388 - recall: 0.7776\n",
      "Epoch 27/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0633 - precision: 0.9368 - recall: 0.7933 ETA: 0s - loss: 0.0622 - precision: 0.9421 - recall: 0.82 - ETA: 0s - loss: 0.0629 - precision: 0.9394 - recall - 0s 14us/step - loss: 0.0629 - precision: 0.9348 - recall: 0.7932\n",
      "Epoch 28/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0618 - precision: 0.9383 - recall: 0.7972 0s - loss: 0.0566 - precision: 0.9505 - recall: 0.82 - ETA: 0s - loss: 0.0616 - precision: 0.9408 - recall: 0.80 - ETA: 0s - loss: 0.0626 - precision: 0.9360 - recall: 0.79 - ETA: 0s - loss: 0.0623 - precision: 0.9388 - recall: 0.79 - ETA: 0s - loss: 0.0608 - precision: 0.9410 - recall: 0.79\n",
      "Epoch 29/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0612 - precision: 0.9339 - recall: 0.8000 ETA: 0s - loss: 0.0526 - precision: 0.9520 - recall: 0.81 - ETA: 0s - loss: 0.0574 - precision: 0.9375 - recall: 0.80 - ETA: 0s - loss: 0.0600 - precision: 0.9319 - recall: 0.79 - ETA: 0s - loss: 0.0606 - precision: 0.9312 - recall: 0. - 0s 14us/step - loss: 0.0620 - precision: 0.9355 - recall: 0.7944\n",
      "Epoch 30/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.1233 - precision: 1.0000 - recall: 0.60 - ETA: 0s - loss: 0.0649 - precision: 0.9339 - recall: 0.78 - ETA: 0s - loss: 0.0623 - precision: 0.9432 - recall: 0.78 - ETA: 0s - loss: 0.0617 - precision: 0.9413 - recall: 0.79 - ETA: 0s - loss: 0.0617 - precision: 0.9345 - recall: 0.79 - ETA: 0s - loss: 0.0616 - precision: 0.9350 - recall: 0.79 - 0s 14us/step - loss: 0.0608 - precision: 0.9363 - recall: 0.7955\n",
      "Epoch 31/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0413 - precision: 1.0000 - recall: 0.83 - ETA: 0s - loss: 0.0511 - precision: 0.9474 - recall: 0.82 - ETA: 0s - loss: 0.0568 - precision: 0.9395 - recall: 0.81 - ETA: 0s - loss: 0.0557 - precision: 0.9405 - recall: 0.81 - ETA: 0s - loss: 0.0563 - precision: 0.9422 - recall: 0.81 - ETA: 0s - loss: 0.0597 - precision: 0.9377 - recall: 0.80 - 0s 14us/step - loss: 0.0598 - precision: 0.9334 - recall: 0.7995\n",
      "Epoch 32/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0680 - precision: 1.0000 - recall: 0.80 - ETA: 0s - loss: 0.0597 - precision: 0.9401 - recall: 0.82 - ETA: 0s - loss: 0.0594 - precision: 0.9319 - recall: 0.79 - ETA: 0s - loss: 0.0636 - precision: 0.9315 - recall: 0.79 - ETA: 0s - loss: 0.0611 - precision: 0.9324 - recall: 0.79 - ETA: 0s - loss: 0.0604 - precision: 0.9356 - recall: 0.80 - 0s 14us/step - loss: 0.0602 - precision: 0.9354 - recall: 0.8013\n",
      "Epoch 33/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0562 - precision: 0.9416 - recall: 0.8043 ETA: 0s - loss: 0.0537 - precision: 0.9516 - recall: 0.82 - ETA: 0s - loss: 0.0555 - precision: 0.9347 - recall:  - ETA: 0s - loss: 0.0581 - precision: 0.9384 - recall: 0.80 - 0s 14us/step - loss: 0.0580 - precision: 0.9368 - recall: 0.8030\n",
      "Epoch 34/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0562 - precision: 0.9452 - recall: 0.8146 ETA: 0s - loss: 0.0546 - precision: 0.9526 - recall: 0.80 - ETA: 0s - loss: 0.0563 - precision: 0.9429 - recall: 0. - ETA: 0s - loss: 0.0562 - precision: 0.9474 - recall: 0. - 0s 14us/step - loss: 0.0577 - precision: 0.9418 - recall: 0.8111\n",
      "Epoch 35/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0557 - precision: 0.9421 - recall: 0.8065 0s - loss: 0.0563 - precision: 0.9529 - recall: 0.79 - ETA: 0s - loss: 0.0557 - precision: 0.9411 - recall: 0. - ETA: 0s - loss: 0.0557 - precision: 0.9423 - recall: 0.80 - ETA: 0s - loss: 0.0556 - precision: 0.9434 - recall: 0.80\n",
      "Epoch 36/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0566 - precision: 0.9363 - recall: 0.8114 ETA: 0s - loss: 0.0567 - precision: 0.9259 - recall: 0.82 - ETA: 0s - loss: 0.0571 - precision: 0.9321 - recall: 0.81 - ETA: 0s - loss: 0.0540 - precision: 0.9336 - recall: 0.82 - ETA: 0s - loss: 0.0549 - precision: 0.9369 - recall: 0. - 0s 14us/step - loss: 0.0558 - precision: 0.9375 - recall: 0.8128\n",
      "Epoch 37/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0541 - precision: 0.9372 - recall: 0.8184 ETA: 0s - loss: 0.0531 - precision: 0.9352 - recall:  - ETA: 0s - loss: 0.0540 - precision: 0.9394 - recall: 0.81 - 0s 14us/step - loss: 0.0543 - precision: 0.9410 - recall: 0.8180\n",
      "Epoch 38/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0552 - precision: 0.9402 - recall: 0.8157 0s - loss: 0.0522 - precision: 0.9532 - recall: 0.82 - ETA: 0s - loss: 0.0533 - precision: 0.9510 - recall: 0.81 - ETA: 0s - loss: 0.0542 - precision: 0.9471 - recall: 0.81 - ETA: 0s - loss: 0.0544 - precision: 0.9404 - recall: 0.81\n",
      "Epoch 39/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0535 - precision: 0.9422 - recall: 0.8311 ETA: 0s - loss: 0.0492 - precision: 0.9724 - recall: 0.84 - ETA: 0s - loss: 0.0510 - precision: 0.9565 - recall: 0.83 - ETA: 0s - loss: 0.0516 - precision: 0.9452 - recall: 0. - ETA: 0s - loss: 0.0533 - precision: 0.9402 - recall: 0.82 - 0s 14us/step - loss: 0.0536 - precision: 0.9390 - recall: 0.8249\n",
      "Epoch 40/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0517 - precision: 0.9461 - recall: 0.8263 ETA: 0s - loss: 0.0499 - precision: 0.9550 - recall: 0.83 - ETA: 0s - loss: 0.0500 - precision: 0.9512 - recall:  - 0s 14us/step - loss: 0.0524 - precision: 0.9444 - recall: 0.8220\n",
      "Epoch 41/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0497 - precision: 0.9466 - recall: 0.8352 ETA: 0s - loss: 0.0470 - precision: 0.9623 - recall: 0. - ETA: 0s - loss: 0.0496 - precision: 0.9465 - recall: 0. - ETA: 0s - loss: 0.0509 - precision: 0.9414 - recall: 0.83 - 0s 14us/step - loss: 0.0520 - precision: 0.9416 - recall: 0.8260\n",
      "Epoch 42/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0492 - precision: 1.0000 - recall: 0.90 - ETA: 0s - loss: 0.0437 - precision: 0.9590 - recall: 0.85 - ETA: 0s - loss: 0.0450 - precision: 0.9461 - recall: 0.84 - ETA: 0s - loss: 0.0485 - precision: 0.9424 - recall: 0.83 - ETA: 0s - loss: 0.0480 - precision: 0.9450 - recall: 0.83 - ETA: 0s - loss: 0.0498 - precision: 0.9457 - recall: 0.82 - 0s 14us/step - loss: 0.0509 - precision: 0.9418 - recall: 0.8289\n",
      "Epoch 43/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.1049 - precision: 1.0000 - recall: 0.61 - ETA: 0s - loss: 0.0517 - precision: 0.9446 - recall: 0.82 - ETA: 0s - loss: 0.0503 - precision: 0.9452 - recall: 0.83 - ETA: 0s - loss: 0.0503 - precision: 0.9467 - recall: 0.83 - ETA: 0s - loss: 0.0502 - precision: 0.9499 - recall: 0.83 - ETA: 0s - loss: 0.0496 - precision: 0.9499 - recall: 0.83 - 0s 14us/step - loss: 0.0498 - precision: 0.9490 - recall: 0.8353\n",
      "Epoch 44/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0495 - precision: 0.9454 - recall: 0.8414 ETA: 0s - loss: 0.0494 - precision: 0.9388 - recall: 0.84 - ETA: 0s - loss: 0.0496 - precision: 0.9436 - recall: 0. - 0s 14us/step - loss: 0.0498 - precision: 0.9425 - recall: 0.8410\n",
      "Epoch 45/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0447 - precision: 0.9552 - recall: 0.8435 ETA: 0s - loss: 0.0449 - precision: 0.9564 - recall: 0. - ETA: 0s - loss: 0.0465 - precision: 0.9498 - recall: 0.84 - ETA: 0s - loss: 0.0493 - precision: 0.9445 - recall: 0.83 - ETA: 0s - loss: 0.0492 - precision: 0.9493 - recall: 0.84 - 0s 14us/step - loss: 0.0493 - precision: 0.9487 - recall: 0.8416\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0484 - precision: 0.9511 - recall: 0.8396 ETA: 0s - loss: 0.0476 - precision: 0.9477 - recall: 0.84 - ETA: 0s - loss: 0.0465 - precision: 0.9539 - recall: 0.84 - ETA: 0s - loss: 0.0470 - precision: 0.9484 - recall: 0.84 - ETA: 0s - loss: 0.0476 - precision: 0.9510 - recall: 0. - 0s 14us/step - loss: 0.0482 - precision: 0.9474 - recall: 0.8404\n",
      "Epoch 47/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0478 - precision: 0.9476 - recall: 0.8497 ETA: 0s - loss: 0.0548 - precision: 0.9341 - recall: 0.82 - ETA: 0s - loss: 0.0507 - precision: 0.9431 - recall: 0. - ETA: 0s - loss: 0.0488 - precision: 0.9430 - recall: 0.84 - ETA: 0s - loss: 0.0485 - precision: 0.9421 - recall: 0.84 - 0s 13us/step - loss: 0.0480 - precision: 0.9414 - recall: 0.8427\n",
      "Epoch 48/100\n",
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0471 - precision: 0.9432 - recall: 0.8422 0s - loss: 0.0409 - precision: 0.9562 - recall: 0.85 - ETA: 0s - loss: 0.0436 - precision: 0.9536 - recall: 0. - ETA: 0s - loss: 0.0460 - precision: 0.9417 - recall: 0.\n",
      "Epoch 49/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0447 - precision: 0.9427 - recall: 0.8485 ETA: 0s - loss: 0.0454 - precision: 0.9422 - recall: 0.84 - ETA: 0s - loss: 0.0438 - precision: 0.9451 - recall: 0. - ETA: 0s - loss: 0.0463 - precision: 0.9412 - recall: 0.83 - 0s 14us/step - loss: 0.0469 - precision: 0.9402 - recall: 0.8416\n",
      "Epoch 50/100\n",
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0462 - precision: 0.9430 - recall: 0.8479 0s - loss: 0.0382 - precision: 0.9678 - recall: 0.87 - ETA: 0s - loss: 0.0399 - precision: 0.9406 - recall: 0.87 - ETA: 0s - loss: 0.0432 - precision: 0.9394 - recall: 0.86 - ETA: 0s - loss: 0.0443 - precision: 0.9404 - recall: 0.\n",
      "Epoch 51/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0453 - precision: 0.9436 - recall: 0.8474 0s - loss: 0.0422 - precision: 0.9537 - recall: 0. - ETA: 0s - loss: 0.0449 - precision: 0.9451 - recall: 0.85\n",
      "Epoch 52/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0424 - precision: 0.9481 - recall: 0.8680 ETA: 0s - loss: 0.0458 - precision: 0.9477 - recall:  - ETA: 0s - loss: 0.0439 - precision: 0.9522 - recall: 0.85 - ETA: 0s - loss: 0.0448 - precision: 0.9483 - recall: 0.85 - 0s 14us/step - loss: 0.0449 - precision: 0.9489 - recall: 0.8561\n",
      "Epoch 53/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0437 - precision: 0.9491 - recall: 0.8558 ETA: 0s - loss: 0.0471 - precision: 0.9477 - recall: 0.84 - ETA: 0s - loss: 0.0458 - precision: 0.9525 - recall: 0.85 - ETA: 0s - loss: 0.0441 - precision: 0.9509 - recall: 0. - 0s 14us/step - loss: 0.0450 - precision: 0.9473 - recall: 0.8485\n",
      "Epoch 54/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0409 - precision: 0.9523 - recall: 0.86 - ETA: 0s - loss: 0.0415 - precision: 0.9544 - recall: 0.85 - ETA: 0s - loss: 0.0416 - precision: 0.9562 - recall: 0.85 - ETA: 0s - loss: 0.0437 - precision: 0.9531 - recall: 0.85 - 0s 14us/step - loss: 0.0440 - precision: 0.9495 - recall: 0.8548\n",
      "Epoch 55/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0428 - precision: 0.9460 - recall: 0.8577 0s - loss: 0.0451 - precision: 0.9514 - reca\n",
      "Epoch 56/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0416 - precision: 0.9502 - recall: 0.8687 0s - loss: 0.0421 - precision: 0.9659 - recall: 0.88 - ETA: 0s - loss: 0.0412 - precision: 0.9580 - recall: 0.87 - ETA: 0s - loss: 0.0409 - precision: 0.9564 - recall: 0. - ETA: 0s - loss: 0.0417 - precision: 0.9515 - recall: 0.86\n",
      "Epoch 57/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0422 - precision: 0.9457 - recall: 0.8656 ETA: 0s - loss: 0.0401 - precision: 0.9496 - recall: 0. - ETA: 0s - loss: 0.0437 - precision: 0.9465 - recall: 0.85 - ETA: 0s - loss: 0.0429 - precision: 0.9462 - recall: 0.85 - 0s 14us/step - loss: 0.0430 - precision: 0.9450 - recall: 0.8520\n",
      "Epoch 58/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0373 - precision: 0.9516 - recall: 0.8783 ETA: 0s - loss: 0.0386 - precision: 0.9560 - recall: 0. - ETA: 0s - loss: 0.0388 - precision: 0.9530 - recall: 0.87 - ETA: 0s - loss: 0.0407 - precision: 0.9480 - recall: 0.87 - ETA: 0s - loss: 0.0419 - precision: 0.9458 - recall: 0.86 - 0s 14us/step - loss: 0.0415 - precision: 0.9483 - recall: 0.8658\n",
      "Epoch 59/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0307 - precision: 1.0000 - recall: 0.85 - ETA: 0s - loss: 0.0415 - precision: 0.9454 - recall: 0.87 - ETA: 0s - loss: 0.0393 - precision: 0.9527 - recall: 0.87 - ETA: 0s - loss: 0.0396 - precision: 0.9517 - recall: 0.87 - ETA: 0s - loss: 0.0410 - precision: 0.9523 - recall: 0.87 - ETA: 0s - loss: 0.0404 - precision: 0.9520 - recall: 0.87 - 0s 13us/step - loss: 0.0406 - precision: 0.9514 - recall: 0.8675\n",
      "Epoch 60/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0134 - precision: 1.0000 - recall: 1.00 - ETA: 0s - loss: 0.0350 - precision: 0.9652 - recall: 0.88 - ETA: 0s - loss: 0.0416 - precision: 0.9581 - recall: 0.86 - ETA: 0s - loss: 0.0397 - precision: 0.9545 - recall: 0.87 - ETA: 0s - loss: 0.0403 - precision: 0.9481 - recall: 0.87 - ETA: 0s - loss: 0.0408 - precision: 0.9460 - recall: 0.87 - 0s 13us/step - loss: 0.0409 - precision: 0.9474 - recall: 0.8721\n",
      "Epoch 61/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0374 - precision: 0.9561 - recall: 0.8775 ETA: 0s - loss: 0.0401 - precision: 0.9522 - recall: 0. - ETA: 0s - loss: 0.0383 - precision: 0.9508 - recall: 0.87 - ETA: 0s - loss: 0.0390 - precision: 0.9501 - recall: 0.87 - ETA: 0s - loss: 0.0396 - precision: 0.9511 - recall: 0.87 - 0s 14us/step - loss: 0.0395 - precision: 0.9519 - recall: 0.8773\n",
      "Epoch 62/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0382 - precision: 0.9542 - recall: 0.8709 ETA: 0s - loss: 0.0367 - precision: 0.9626 - recall - 0s 14us/step - loss: 0.0390 - precision: 0.9532 - recall: 0.8675\n",
      "Epoch 63/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0377 - precision: 0.9482 - recall: 0.8824 ETA: 0s - loss: 0.0346 - precision: 0.9570 - recall: 0.88 - ETA: 0s - loss: 0.0366 - precision: 0.9503 - recall: 0.88 - ETA: 0s - loss: 0.0367 - precision: 0.9502 - recall: 0. - 0s 14us/step - loss: 0.0385 - precision: 0.9490 - recall: 0.8785\n",
      "Epoch 64/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0384 - precision: 0.9562 - recall: 0.8760 ETA: 0s - loss: 0.0379 - precision: 0.9561 - recall: 0.88 - ETA: 0s - loss: 0.0385 - precision: 0.9567 - recall - 0s 14us/step - loss: 0.0381 - precision: 0.9567 - recall: 0.8779\n",
      "Epoch 65/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0394 - precision: 0.9491 - recall: 0.8802 0s - loss: 0.0331 - precision: 0.9665 - recall: 0.86 - ETA: 0s - loss: 0.0367 - precision: 0.9589 - recall: 0.87 - ETA: 0s - loss: 0.0389 - precision: 0.9467 - recall: 0.88 - ETA: 0s - loss: 0.0381 - precision: 0.9475 - recall: 0.88 - ETA: 0s - loss: 0.0391 - precision: 0.9494 - recall: 0.88\n",
      "Epoch 66/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0428 - precision: 0.9309 - recall: 0.87 - ETA: 0s - loss: 0.0404 - precision: 0.9480 - recall: 0.86 - ETA: 0s - loss: 0.0387 - precision: 0.9535 - recall: 0.87 - ETA: 0s - loss: 0.0377 - precision: 0.9571 - recall: 0.87 - ETA: 0s - loss: 0.0374 - precision: 0.9576 - recall: 0.87 - 0s 14us/step - loss: 0.0375 - precision: 0.9553 - recall: 0.8750\n",
      "Epoch 67/100\n",
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0369 - precision: 0.9544 - recall: 0.8797 0s - loss: 0.0338 - precision: 0.9610 - recall: 0.88 - ETA: 0s - loss: 0.0355 - precision: 0.9570 - recall: 0.88 - ETA: 0s - loss: 0.0362 - precision: 0.9526 - recall: 0.88 - ETA: 0s - loss: 0.0363 - precision: 0.9549 - recall: 0.88\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0367 - precision: 0.9581 - recall: 0.8825 0s - loss: 0.0328 - precision: 0.9709 - recall: 0.89 - ETA: 0s - loss: 0.0356 - precision: 0.9648 - recall: 0.89 - ETA: 0s - loss: 0.0362 - precision: 0.9556 - recall: 0.88\n",
      "Epoch 69/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0364 - precision: 0.9487 - recall: 0.8855 ETA: 0s - loss: 0.0338 - precision: 0.9515 - recall: 0.91 - ETA: 0s - loss: 0.0351 - precision: 0.9488 - recall: 0.89 - ETA: 0s - loss: 0.0354 - precision: 0.9573 - recall: 0. - ETA: 0s - loss: 0.0367 - precision: 0.9469 - recall: 0.88 - 0s 14us/step - loss: 0.0367 - precision: 0.9481 - recall: 0.8842\n",
      "Epoch 70/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0352 - precision: 0.9543 - recall: 0.8785 0s - loss: 0.0326 - precision: 0.9639 - recall: 0.87 - ETA: 0s - loss: 0.0351 - precision: 0.9544 - recall: 0.87 - ETA: 0s - loss: 0.0348 - precision: 0.9540 - recall: 0.\n",
      "Epoch 71/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0334 - precision: 0.9572 - recall: 0.8889 ETA: 0s - loss: 0.0299 - precision: 0.9630 - recall: 0. - ETA: 0s - loss: 0.0339 - precision: 0.9594 - recall: 0. - ETA: 0s - loss: 0.0348 - precision: 0.9549 - recall: 0.88 - 0s 14us/step - loss: 0.0353 - precision: 0.9553 - recall: 0.8859\n",
      "Epoch 72/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0348 - precision: 0.9595 - recall: 0.8865 0s - loss: 0.0291 - precision: 0.9635 - recall: 0. - ETA: 0s - loss: 0.0349 - precision: 0.9616 - recall: 0.89 - ETA: 0s - loss: 0.0346 - precision: 0.9604 - recall: 0.89 - ETA: 0s - loss: 0.0347 - precision: 0.9608 - recall: 0.88\n",
      "Epoch 73/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0333 - precision: 0.9596 - recall: 0.8946 ETA: 0s - loss: 0.0327 - precision: 0.9589 - recall: 0.90 - ETA: 0s - loss: 0.0330 - precision: 0.9519 - recall: 0. - ETA: 0s - loss: 0.0341 - precision: 0.9586 - recall: 0. - 0s 14us/step - loss: 0.0342 - precision: 0.9591 - recall: 0.8911\n",
      "Epoch 74/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0338 - precision: 0.9594 - recall: 0.8854 0s - loss: 0.0358 - precision: 0.9647 - recall: 0.90 - ETA: 0s - loss: 0.0338 - precision: 0.9563 - recall: 0.90 - ETA: 0s - loss: 0.0326 - precision: 0.9595 - recall: 0.89 - ETA: 0s - loss: 0.0340 - precision: 0.9605 - recall: 0.\n",
      "Epoch 75/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0334 - precision: 0.9453 - recall: 0.8801 ETA: 0s - loss: 0.0319 - precision: 0.9294 - recall: 0. - ETA: 0s - loss: 0.0341 - precision: 0.9509 - recall: 0.89 - ETA: 0s - loss: 0.0329 - precision: 0.9575 - recall: 0.89 - ETA: 0s - loss: 0.0327 - precision: 0.9633 - recall: 0.89 - 0s 14us/step - loss: 0.0331 - precision: 0.9593 - recall: 0.8963\n",
      "Epoch 76/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0217 - precision: 1.0000 - recall: 1.00 - ETA: 0s - loss: 0.0276 - precision: 0.9867 - recall: 0.90 - ETA: 0s - loss: 0.0311 - precision: 0.9789 - recall: 0.90 - ETA: 0s - loss: 0.0309 - precision: 0.9711 - recall: 0.90 - ETA: 0s - loss: 0.0317 - precision: 0.9700 - recall: 0.89 - ETA: 0s - loss: 0.0325 - precision: 0.9654 - recall: 0.89 - 0s 14us/step - loss: 0.0324 - precision: 0.9647 - recall: 0.8969\n",
      "Epoch 77/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0319 - precision: 0.9579 - recall: 0.89 - ETA: 0s - loss: 0.0322 - precision: 0.9577 - recall: 0.88 - ETA: 0s - loss: 0.0328 - precision: 0.9559 - recall: 0.89 - 0s 14us/step - loss: 0.0326 - precision: 0.9557 - recall: 0.8952\n",
      "Epoch 78/100\n",
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0318 - precision: 0.9602 - recall: 0.9036 0s - loss: 0.0265 - precision: 0.9784 - recall: 0.92 - ETA: 0s - loss: 0.0280 - precision: 0.9712 - recall:  - ETA: 0s - loss: 0.0317 - precision: 0.9593 - recall: 0.90\n",
      "Epoch 79/100\n",
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0323 - precision: 0.9545 - recall: 0.9056 0s - loss: 0.0306 - precision: 0.9572 - recall: 0.90 - ETA: 0s - loss: 0.0305 - precision: 0.9599 - recall: 0.90 - ETA: 0s - loss: 0.0322 - precision: 0.9574 - recall: 0.90\n",
      "Epoch 80/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0308 - precision: 0.9638 - recall: 0.9038 0s - loss: 0.0309 - precision: 0.9635 - recall: 0.90\n",
      "Epoch 81/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0298 - precision: 0.9602 - recall: 0.9094 ETA: 0s - loss: 0.0252 - precision: 0.9704 - recall: 0.93 - ETA: 0s - loss: 0.0288 - precision: 0.9575 - recall: 0. - ETA: 0s - loss: 0.0289 - precision: 0.9630 - recall: 0. - 0s 14us/step - loss: 0.0303 - precision: 0.9627 - recall: 0.9079\n",
      "Epoch 82/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0322 - precision: 0.9587 - recall: 0.9056 ETA: 0s - loss: 0.0329 - precision: 0.9435 - recall: 0.88 - ETA: 0s - loss: 0.0304 - precision: 0.9507 - recall: 0.90 - ETA: 0s - loss: 0.0307 - precision: 0.9523 - recall: 0.90 - ETA: 0s - loss: 0.0308 - precision: 0.9574 - recall: 0. - 0s 13us/step - loss: 0.0318 - precision: 0.9592 - recall: 0.9067\n",
      "Epoch 83/100\n",
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0291 - precision: 0.9669 - recall: 0.9090 0s - loss: 0.0269 - precision: 0.9776 - reca\n",
      "Epoch 84/100\n",
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0315 - precision: 0.9589 - recall: 0.8998 0s - loss: 0.0302 - precision: 0.9659 - recall: 0.90 - ETA: 0s - loss: 0.0294 - precision: 0.9675 - recall: 0.90 - ETA: 0s - loss: 0.0299 - precision: 0.9651 - recall: 0.90 - ETA: 0s - loss: 0.0314 - precision: 0.9581 - recall: 0.90\n",
      "Epoch 85/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0299 - precision: 0.9629 - recall: 0.9095 ETA: 0s - loss: 0.0313 - precision: 0.9585 - recall: 0. - ETA: 0s - loss: 0.0292 - precision: 0.9616 - recall: 0.90 - ETA: 0s - loss: 0.0296 - precision: 0.9628 - recall: 0.90 - ETA: 0s - loss: 0.0302 - precision: 0.9575 - recall: 0.89 - 0s 13us/step - loss: 0.0303 - precision: 0.9587 - recall: 0.8952\n",
      "Epoch 86/100\n",
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0281 - precision: 0.9642 - recall: 0.9159 0s - loss: 0.0287 - precision: 0.9608 - recall: 0.91 - ETA: 0s - loss: 0.0275 - precision: 0.9711 - recall: 0.91 - ETA: 0s - loss: 0.0287 - precision: 0.9678 - recall: 0.91 - ETA: 0s - loss: 0.0288 - precision: 0.9655 - recall: 0.\n",
      "Epoch 87/100\n",
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0285 - precision: 0.9659 - recall: 0.9143 0s - loss: 0.0249 - precision: 0.9697 - recall: 0. - ETA: 0s - loss: 0.0276 - precision: 0.9699 - recall: 0.91 - ETA: 0s - loss: 0.0284 - precision: 0.9647 - recall: 0.91\n",
      "Epoch 88/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0252 - precision: 0.9748 - recall: 0.9196 ETA: 0s - loss: 0.0246 - precision: 0.9829 - recall: 0. - ETA: 0s - loss: 0.0273 - precision: 0.9701 - recall: 0.91 - ETA: 0s - loss: 0.0282 - precision: 0.9694 - recall: 0.90 - ETA: 0s - loss: 0.0289 - precision: 0.9651 - recall: 0.91 - 0s 13us/step - loss: 0.0284 - precision: 0.9658 - recall: 0.9107\n",
      "Epoch 89/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0295 - precision: 0.9648 - recall: 0.91 - ETA: 0s - loss: 0.0297 - precision: 0.9625 - recall: 0.91 - ETA: 0s - loss: 0.0302 - precision: 0.9605 - recall: 0.91 - 0s 13us/step - loss: 0.0308 - precision: 0.9605 - recall: 0.9101\n",
      "Epoch 90/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0103 - precision: 1.0000 - recall: 1.00 - ETA: 0s - loss: 0.0238 - precision: 0.9778 - recall: 0.92 - ETA: 0s - loss: 0.0262 - precision: 0.9724 - recall: 0.92 - ETA: 0s - loss: 0.0263 - precision: 0.9710 - recall: 0.92 - ETA: 0s - loss: 0.0265 - precision: 0.9739 - recall: 0.92 - ETA: 0s - loss: 0.0271 - precision: 0.9730 - recall: 0.92 - 0s 13us/step - loss: 0.0271 - precision: 0.9733 - recall: 0.9222\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0264 - precision: 0.9643 - recall: 0.9161 ETA: 0s - loss: 0.0255 - precision: 0.9683 - recall: 0. - 0s 14us/step - loss: 0.0276 - precision: 0.9648 - recall: 0.9159\n",
      "Epoch 92/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0264 - precision: 0.9696 - recall: 0.9188 0s - loss: 0.0284 - precision: 0.9598 - recall: 0.91 - ETA: 0s - loss: 0.0259 - precision: 0.9615 - recall: 0.92 - ETA: 0s - loss: 0.0263 - precision: 0.9644 - recall: \n",
      "Epoch 93/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0270 - precision: 0.9655 - recall: 0.9199 0s - loss: 0.0228 - precision: 0.9637 - recall: 0. - ETA: 0s - loss: 0.0268 - precision: 0.9646 - recall: 0.92 - ETA: 0s - loss: 0.0261 - precision: 0.9680 - recall: 0.\n",
      "Epoch 94/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0060 - precision: 1.0000 - recall: 1.00 - ETA: 0s - loss: 0.0225 - precision: 0.9765 - recall: 0.91 - ETA: 0s - loss: 0.0229 - precision: 0.9751 - recall: 0.92 - ETA: 0s - loss: 0.0234 - precision: 0.9724 - recall: 0.92 - ETA: 0s - loss: 0.0250 - precision: 0.9693 - recall: 0.92 - ETA: 0s - loss: 0.0251 - precision: 0.9707 - recall: 0.92 - 0s 14us/step - loss: 0.0262 - precision: 0.9648 - recall: 0.9165\n",
      "Epoch 95/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0268 - precision: 0.9659 - recall: 0.9216 ETA: 0s - loss: 0.0191 - precision: 0.9778 - reca - 0s 14us/step - loss: 0.0266 - precision: 0.9668 - recall: 0.9217\n",
      "Epoch 96/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0256 - precision: 0.9639 - recall: 0.9217 0s - loss: 0.0267 - precision: 0.9736 - recall: 0.92 - ETA: 0s - loss: 0.0249 - precision: 0.9732 - recall: 0.92 - ETA: 0s - loss: 0.0241 - precision: 0.9747 - recall: 0. - ETA: 0s - loss: 0.0251 - precision: 0.9637 - recall: 0.92\n",
      "Epoch 97/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0253 - precision: 0.9643 - recall: 0.9171 0s - loss: 0.0248 - precision: 0.9601 - recall: 0.92 - ETA: 0s - loss: 0.0250 - precision: 0.9631 - recall: 0.91\n",
      "Epoch 98/100\n",
      "20522/20522 [==============================] - 0s 14us/step - loss: 0.0245 - precision: 0.9710 - recall: 0.9264 0s - loss: 0.0211 - precision: 0.9767 - recall: 0.93 - ETA: 0s - loss: 0.0228 - precision: 0.9727 - recall: 0. - ETA: 0s - loss: 0.0247 - precision: 0.9693 - recall: 0.92\n",
      "Epoch 99/100\n",
      "20522/20522 [==============================] - 0s 13us/step - loss: 0.0252 - precision: 0.9651 - recall: 0.9251 0s - loss: 0.0240 - precision: 0.9688 - recall: 0.92 - ETA: 0s - loss: 0.0247 - precision: 0.9715 - recall: \n",
      "Epoch 100/100\n",
      "20522/20522 [==============================] - ETA: 0s - loss: 0.0237 - precision: 0.9701 - recall: 0.9309 ETA: 0s - loss: 0.0241 - precision: 0.9653 - recall:  - ETA: 0s - loss: 0.0240 - precision: 0.9690 - recall: 0. - 0s 14us/step - loss: 0.0235 - precision: 0.9700 - recall: 0.9303\n"
     ]
    }
   ],
   "source": [
    "inputl:inp[`shape pykw enlist 51]\n",
    "hidden1:dense[40;`activation pykw `relu][inputl]\n",
    "hidden2:dense[40;`activation pykw `relu][hidden1]\n",
    "o:dense[1;`activation pykw `sigmoid][hidden2]\n",
    "\n",
    "modl:models[`inputs pykw inputl;`outputs pykw o]\n",
    "modl[`:compile][`optimizer pykw \"adam\";`loss pykw \"binary_crossentropy\";`metrics pykw (km[`:binary_precision][]`;km[`:binary_recall][]`)];\n",
    "modl[`:summary][];\n",
    "\n",
    "res:modl[`:fit][array[xtr];ytr;`batch_size pykw 100;`verbose pykw 1;`epochs pykw 100];\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001483858 1.490116e-07 0.005833924 0.0002307594 0.01736081 2.086163e-07 0...\n"
     ]
    }
   ],
   "source": [
    "show nnPred:raze(modl[`:predict]array[mattab xtest])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss     | 0.1750883 0.1148755 0.1061981 0.1011553 0.09711752 0.09459616 0.09..\n",
      "precision| 0.9095982 0.9188256 0.9221106 0.9227609 0.9315403  0.9238095  0.92..\n",
      "recall   | 0.46947   0.6129032 0.6342166 0.6468894 0.6584101  0.6705069  0.67..\n",
      "loss     | 0.1750883 0.1148755 0.1061981 0.1011553 0.09711752 0.09459616 0.09..\n",
      "precision| 0.9095982 0.9188256 0.9221106 0.9227609 0.9315403  0.9238095  0.92..\n",
      "recall   | 0.46947   0.6129032 0.6342166 0.6468894 0.6584101  0.6705069  0.67..\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 460.8x345.6 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 0.8990127\n",
      "The mean_class_accuracy of the model is 0.7110373\n"
     ]
    }
   ],
   "source": [
    "show hist:6#(res[`:history]`)\n",
    "\n",
    "plt[`:plot]hist`loss;\n",
    "plt[`:plot]hist`val_loss;\n",
    "plt[`:title]\"model loss\";\n",
    "plt[`:ylabel]\"loss\";\n",
    "plt[`:xlabel]\"epoch\";\n",
    "plt[`:show][];\n",
    "\n",
    "conf:.ml.confdict[ytest;0.5<nnPred;1b]\n",
    "\n",
    "\n",
    "acc:(count where (0.5<nnPred)=ytest)%count[ytest]\n",
    "meanclassavg:avg (conf[`tp]%(sum conf[`tp`fn]);conf[`tn]%(sum conf[`tn`fp]))\n",
    "-1\"The accuracy of the model is \",string acc;\n",
    "-1\"The mean_class_accuracy of the model is \",string meanclassavg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnfM:.ml.confmat[ytest;0.5<nnPred]\n",
    ".ml.displayCM[value cnfM;`Low`High;\"Test Set Confusion Matrix\";()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q (kdb+)",
   "language": "q",
   "name": "qpk"
  },
  "language_info": {
   "file_extension": ".q",
   "mimetype": "text/x-q",
   "name": "q",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
